{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "337afa5f-276d-48b2-90d1-f2d159e46c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9356fa3c-2949-4fd3-8e4d-6d7522a9e948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atom Types: ['Fe', 'B', 'N', 'C', 'C', 'N', 'C', 'C', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'O', 'H', 'H', 'O', 'H', 'H', 'O', 'H', 'H', 'O', 'H', 'H', 'O', 'H', 'H']\n",
      "Coordinates Tensor: tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  2.1000, -0.0000],\n",
      "        [-1.3158,  2.8750,  0.2655],\n",
      "        [-1.6295,  3.7201, -0.8956],\n",
      "        [-2.4111,  1.9197,  0.4865],\n",
      "        [ 1.3158,  2.8750, -0.2655],\n",
      "        [ 2.4111,  1.9198, -0.4865],\n",
      "        [ 1.1548,  3.7201, -1.4574],\n",
      "        [-1.7468,  3.1050, -1.7632],\n",
      "        [-2.5379,  4.2551, -0.7124],\n",
      "        [-0.8323,  4.4154, -1.0565],\n",
      "        [-2.5283,  1.3046, -0.3811],\n",
      "        [-2.1827,  1.3046,  1.3317],\n",
      "        [-3.3194,  2.4547,  0.6698],\n",
      "        [ 2.1827,  1.3046, -1.3317],\n",
      "        [ 3.3194,  2.4548, -0.6698],\n",
      "        [ 2.5283,  1.3046,  0.3811],\n",
      "        [ 0.9264,  3.1050, -2.3026],\n",
      "        [ 0.3575,  4.4154, -1.2966],\n",
      "        [ 2.0631,  4.2551, -1.6407],\n",
      "        [ 2.0800, -0.0000, -0.0000],\n",
      "        [ 2.7151, -0.0726,  0.7690],\n",
      "        [ 2.6655,  0.0726, -0.7690],\n",
      "        [-0.0000, -2.0800,  0.0000],\n",
      "        [-0.0993, -2.7151,  0.7660],\n",
      "        [ 0.0993, -2.6655, -0.7660],\n",
      "        [-2.0800,  0.0000,  0.0000],\n",
      "        [-2.7151, -0.0726, -0.7690],\n",
      "        [-2.6655,  0.0726,  0.7690],\n",
      "        [ 0.0000,  0.0000,  2.0800],\n",
      "        [-0.7660, -0.0993,  2.7151],\n",
      "        [ 0.7660,  0.0993,  2.6655],\n",
      "        [ 0.0000, -0.0000, -2.0800],\n",
      "        [ 0.7711, -0.0455, -2.7151],\n",
      "        [-0.7711,  0.0455, -2.6655]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def read_xyz(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    atom_count = int(lines[0].strip())\n",
    "    comment = lines[1].strip()\n",
    "    \n",
    "    atom_types = []\n",
    "    coordinates = []\n",
    "    for line in lines[2:]:\n",
    "        parts = line.split()\n",
    "        if len(parts) == 4:\n",
    "            atom_types.append(parts[0])\n",
    "            coordinates.append([float(parts[1]), float(parts[2]), float(parts[3])])\n",
    "    \n",
    "    return atom_types, np.array(coordinates)\n",
    "\n",
    "# Example usage\n",
    "file_path = '/Users/victorsu-ortiz/Desktop/Fe-Boryl_complexes/data/xyz_molsimp/monosubstituted_0001.xyz'\n",
    "atom_types, coordinates = read_xyz(file_path)\n",
    "tensor = torch.tensor(coordinates)\n",
    "\n",
    "print(\"Atom Types:\", atom_types)\n",
    "print(\"Coordinates Tensor:\", tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3a23035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Index: tensor([[ 2,  3,  2,  4,  3,  8,  3,  9,  3, 10,  4, 11,  4, 12,  4, 13,  5,  6,\n",
      "          5,  7,  6, 14,  6, 15,  6, 16,  7, 17,  7, 18,  7, 19, 10, 18, 11, 26,\n",
      "         11, 27, 12, 28, 14, 22, 16, 20, 16, 21, 20, 21, 20, 22, 23, 24, 23, 25,\n",
      "         26, 27, 26, 28, 29, 30, 29, 31, 32, 33, 32, 34],\n",
      "        [ 3,  2,  4,  2,  8,  3,  9,  3, 10,  3, 11,  4, 12,  4, 13,  4,  6,  5,\n",
      "          7,  5, 14,  6, 15,  6, 16,  6, 17,  7, 18,  7, 19,  7, 18, 10, 26, 11,\n",
      "         27, 11, 28, 12, 22, 14, 20, 16, 21, 16, 21, 20, 22, 20, 24, 23, 25, 23,\n",
      "         27, 26, 28, 26, 30, 29, 31, 29, 33, 32, 34, 32]])\n",
      "Edge Index Shape: torch.Size([2, 66])\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def create_graph(coordinates, threshold=1.5):\n",
    "    num_atoms = coordinates.shape[0]\n",
    "    edge_index = []\n",
    "    \n",
    "    # Calculate pairwise distances\n",
    "    distances = squareform(pdist(coordinates))\n",
    "    \n",
    "    # Create edges based on the distance threshold\n",
    "    for i in range(num_atoms):\n",
    "        for j in range(i + 1, num_atoms):\n",
    "            if distances[i, j] <= threshold:\n",
    "                edge_index.append([i, j])\n",
    "                edge_index.append([j, i])\n",
    "    \n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    return edge_index\n",
    "\n",
    "# Create edge index\n",
    "edge_index = create_graph(coordinates)\n",
    "print(\"Edge Index:\", edge_index)\n",
    "print(\"Edge Index Shape:\", edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77ada0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph data saved to ./data/torch_processed/graph_data.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Assuming `data` is the Data object created previously\n",
    "def save_graph_data(data, file_path):\n",
    "    torch.save(data, file_path)\n",
    "    print(f\"Graph data saved to {file_path}\")\n",
    "\n",
    "# Example usage\n",
    "save_path = './data/torch_processed/graph_data.pth'\n",
    "save_graph_data(edge_index, save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9477de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(3, 16)\n",
      "  (conv2): GCNConv(16, 3)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "num_node_features = 3  # Assuming 3 features per node (x, y, z coordinates)\n",
    "hidden_channels = 16\n",
    "num_classes = 3  # Example number of output classes, modify as needed\n",
    "\n",
    "model = GCN(num_node_features, hidden_channels, num_classes)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cde1e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.0882610082626343\n",
      "Epoch 10, Loss: 1.147044062614441\n",
      "Epoch 20, Loss: 1.1178487539291382\n",
      "Epoch 30, Loss: 1.1612259149551392\n",
      "Epoch 40, Loss: 1.0923107862472534\n",
      "Epoch 50, Loss: 1.073821783065796\n",
      "Epoch 60, Loss: 1.0721259117126465\n",
      "Epoch 70, Loss: 1.0980325937271118\n",
      "Epoch 80, Loss: 1.0845186710357666\n",
      "Epoch 90, Loss: 1.1043436527252197\n",
      "Epoch 100, Loss: 1.086771011352539\n",
      "Epoch 110, Loss: 1.103747844696045\n",
      "Epoch 120, Loss: 1.083693265914917\n",
      "Epoch 130, Loss: 1.0696842670440674\n",
      "Epoch 140, Loss: 1.1011320352554321\n",
      "Epoch 150, Loss: 1.0985819101333618\n",
      "Epoch 160, Loss: 1.1353219747543335\n",
      "Epoch 170, Loss: 1.1184213161468506\n",
      "Epoch 180, Loss: 1.0772175788879395\n",
      "Epoch 190, Loss: 1.1302759647369385\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "# Convert coordinates to tensor\n",
    "coordinates_tensor = torch.tensor(coordinates, dtype=torch.float)\n",
    "\n",
    "# Create the graph data object\n",
    "data = Data(x=coordinates_tensor, edge_index=edge_index)\n",
    "\n",
    "# Training the model (example)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "val_losses = []\n",
    "\n",
    "# Example training loop\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    # Assuming labels are available (for simplicity, using dummy labels here)\n",
    "    labels = torch.randint(0, num_classes, (coordinates_tensor.size(0),))\n",
    "    loss = criterion(out, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "    val_losses.append([epoch+1, loss.item()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "543782c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.7778289318084717\n",
      "Epoch 10, Loss: 2.2074599266052246\n",
      "Epoch 20, Loss: 1.2938276529312134\n",
      "Epoch 30, Loss: 0.9356461763381958\n",
      "Epoch 40, Loss: 0.8730111718177795\n",
      "Epoch 50, Loss: 0.8396367430686951\n",
      "Epoch 60, Loss: 0.8275805711746216\n",
      "Epoch 70, Loss: 0.8168777823448181\n",
      "Epoch 80, Loss: 0.8089335560798645\n",
      "Epoch 90, Loss: 0.8011478781700134\n",
      "Epoch 100, Loss: 0.7924127578735352\n",
      "Epoch 110, Loss: 0.7834661602973938\n",
      "Epoch 120, Loss: 0.7728803753852844\n",
      "Epoch 130, Loss: 0.7564015984535217\n",
      "Epoch 140, Loss: 0.7386890649795532\n",
      "Epoch 150, Loss: 0.724384069442749\n",
      "Epoch 160, Loss: 0.7102684378623962\n",
      "Epoch 170, Loss: 0.6959591507911682\n",
      "Epoch 180, Loss: 0.6804864406585693\n",
      "Epoch 190, Loss: 0.6644735336303711\n",
      "Validation Losses: [[1, 3.7778289318084717], [2, 3.595705270767212], [3, 3.4188263416290283], [4, 3.2470011711120605], [5, 3.080409049987793], [6, 2.919478416442871], [7, 2.7642438411712646], [8, 2.614863872528076], [9, 2.4720184803009033], [10, 2.3361003398895264], [11, 2.2074599266052246], [12, 2.086181402206421], [13, 1.9720929861068726], [14, 1.8651483058929443], [15, 1.7650781869888306], [16, 1.6713848114013672], [17, 1.5839024782180786], [18, 1.5025845766067505], [19, 1.4274110794067383], [20, 1.3579093217849731], [21, 1.2938276529312134], [22, 1.2355118989944458], [23, 1.1826611757278442], [24, 1.1351912021636963], [25, 1.09287691116333], [26, 1.0555431842803955], [27, 1.0229902267456055], [28, 0.995008647441864], [29, 0.9713581800460815], [30, 0.9517021179199219], [31, 0.9356461763381958], [32, 0.922802746295929], [33, 0.9126453399658203], [34, 0.9046310186386108], [35, 0.8982524871826172], [36, 0.8930343985557556], [37, 0.8885993957519531], [38, 0.8846038579940796], [39, 0.8807788491249084], [40, 0.8769375085830688], [41, 0.8730111718177795], [42, 0.8690048456192017], [43, 0.864953339099884], [44, 0.8609479069709778], [45, 0.8571054935455322], [46, 0.853456974029541], [47, 0.8500686287879944], [48, 0.846976101398468], [49, 0.8442029356956482], [50, 0.8417609333992004], [51, 0.8396367430686951], [52, 0.8377761840820312], [53, 0.8361443281173706], [54, 0.8347095251083374], [55, 0.833445131778717], [56, 0.8323245644569397], [57, 0.8313170075416565], [58, 0.8303880095481873], [59, 0.8294923305511475], [60, 0.8285727500915527], [61, 0.8275805711746216], [62, 0.8264975547790527], [63, 0.8253272175788879], [64, 0.8240975737571716], [65, 0.8228495121002197], [66, 0.821627140045166], [67, 0.8204851746559143], [68, 0.8194485306739807], [69, 0.8185202479362488], [70, 0.8176718354225159], [71, 0.8168777823448181], [72, 0.8161163926124573], [73, 0.8153702616691589], [74, 0.8146106600761414], [75, 0.8138287663459778], [76, 0.8130365014076233], [77, 0.8122355937957764], [78, 0.8114164471626282], [79, 0.8105872869491577], [80, 0.8097566962242126], [81, 0.8089335560798645], [82, 0.8081169128417969], [83, 0.8073171377182007], [84, 0.8065266609191895], [85, 0.8057470917701721], [86, 0.8049799799919128], [87, 0.8042197227478027], [88, 0.8034671545028687], [89, 0.8027055263519287], [90, 0.8019306063652039], [91, 0.8011478781700134], [92, 0.8003556132316589], [93, 0.799548864364624], [94, 0.7987268567085266], [95, 0.7979024052619934], [96, 0.7970346212387085], [97, 0.7961371541023254], [98, 0.7952319383621216], [99, 0.7943082451820374], [100, 0.7933670878410339], [101, 0.7924127578735352], [102, 0.7914659380912781], [103, 0.7904963493347168], [104, 0.7895700931549072], [105, 0.7887157201766968], [106, 0.7878478169441223], [107, 0.7869616746902466], [108, 0.7860943675041199], [109, 0.7852226495742798], [110, 0.784349799156189], [111, 0.7834661602973938], [112, 0.7825708985328674], [113, 0.7816641926765442], [114, 0.7807562947273254], [115, 0.7798401117324829], [116, 0.7787811756134033], [117, 0.7777308821678162], [118, 0.776614248752594], [119, 0.7754331231117249], [120, 0.7741788029670715], [121, 0.7728803753852844], [122, 0.7715399861335754], [123, 0.770047128200531], [124, 0.7684069275856018], [125, 0.7667450308799744], [126, 0.7650895714759827], [127, 0.7634204030036926], [128, 0.761738121509552], [129, 0.7600406408309937], [130, 0.7583380937576294], [131, 0.7564015984535217], [132, 0.7544882893562317], [133, 0.7526366114616394], [134, 0.7507972717285156], [135, 0.7489868998527527], [136, 0.7471985220909119], [137, 0.7454308271408081], [138, 0.7436883449554443], [139, 0.7419927716255188], [140, 0.7403299808502197], [141, 0.7386890649795532], [142, 0.7370674014091492], [143, 0.7354751825332642], [144, 0.733895480632782], [145, 0.732333242893219], [146, 0.7307761907577515], [147, 0.7295290231704712], [148, 0.7283041477203369], [149, 0.727042019367218], [150, 0.7257350087165833], [151, 0.724384069442749], [152, 0.7229876518249512], [153, 0.7215495109558105], [154, 0.720076322555542], [155, 0.7185654640197754], [156, 0.7171084880828857], [157, 0.7157217264175415], [158, 0.7143253087997437], [159, 0.7129650712013245], [160, 0.7116114497184753], [161, 0.7102684378623962], [162, 0.708916962146759], [163, 0.7075315117835999], [164, 0.7061157822608948], [165, 0.70467609167099], [166, 0.7032374143600464], [167, 0.701801598072052], [168, 0.7003490328788757], [169, 0.6989023685455322], [170, 0.6974391341209412], [171, 0.6959591507911682], [172, 0.6944603323936462], [173, 0.6929544806480408], [174, 0.6914321780204773], [175, 0.6898930072784424], [176, 0.6883395910263062], [177, 0.6867803931236267], [178, 0.6852089762687683], [179, 0.6836245656013489], [180, 0.6820548176765442], [181, 0.6804864406585693], [182, 0.6789047122001648], [183, 0.6773126721382141], [184, 0.6757103800773621], [185, 0.6741021275520325], [186, 0.6724882125854492], [187, 0.6708935499191284], [188, 0.6692861318588257], [189, 0.6676769256591797], [190, 0.6660753488540649], [191, 0.6644735336303711], [192, 0.6628657579421997], [193, 0.6612613201141357], [194, 0.6596406698226929], [195, 0.6580569744110107], [196, 0.6565360426902771], [197, 0.6549538969993591], [198, 0.653383731842041], [199, 0.6518088579177856], [200, 0.6502271294593811]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b1/89wsk5t517v75qvdm2x4ygwc0000gn/T/ipykernel_60155/486242667.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels_tensor = torch.tensor(labels, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Example graph neural network model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Load data from .pth file\n",
    "data_path = '/Users/victorsu-ortiz/Desktop/Fe-Boryl_complexes/data/torch_processed/graph_data.pth'\n",
    "data = torch.load(data_path)\n",
    "edge_index = data\n",
    "\n",
    "# Convert coordinates and labels to tensor\n",
    "coordinates_tensor = torch.tensor(coordinates, dtype=torch.float)\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Create the graph data object\n",
    "data = Data(x=coordinates_tensor, edge_index=edge_index, y=labels_tensor)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "num_node_features = coordinates_tensor.size(1)\n",
    "num_classes = len(set(labels))\n",
    "model = GCN(num_node_features, num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "val_losses = []\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "    \n",
    "    val_losses.append([epoch+1, loss.item()])\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Print validation losses\n",
    "print(\"Validation Losses:\", val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f59e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'./val_losses/gcn_noxyz', exist_ok=True)\n",
    "with open(f'./val_losses/gcn_noxyz/val_losses.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Epoch', 'Validation Loss'])\n",
    "    writer.writerows(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82ad62ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = \"monosubstituted_0001.xyz\"\n",
    "\n",
    "# Define the regex pattern to extract the number before the file extension\n",
    "pattern = r'_(\\d+)\\.'\n",
    "\n",
    "# Search for the pattern in the file name\n",
    "match = re.search(pattern, file_name)\n",
    "\n",
    "# Extract the number if found\n",
    "if match:\n",
    "    number = match.group(1)\n",
    "    print(number)\n",
    "else:\n",
    "    print(\"No number found in the file name.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f7d9022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph data saved to sample_0001\n"
     ]
    }
   ],
   "source": [
    "def save_graph_data(data, file_path):\n",
    "    torch.save(data, file_path)\n",
    "    print(f\"Graph data saved to {file_path}\")\n",
    "\n",
    "save_graph_data({\"id\": \"001\", \"tensor\": edge_index}, \"sample_0001\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
